{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "data_path = 'D:\\python\\GCN\\DeepGraphClustering\\data'\n",
    "\n",
    "def kmeans(data, n_of_clusters):\n",
    "    n_of_clusters = n_of_clusters.cuda().cpu().detach().numpy().copy()\n",
    "    k_means = KMeans(n_of_clusters, n_init=10, tol=0.0000001)\n",
    "    k_means.fit(data)\n",
    "    kmeans_labels = torch.LongTensor(k_means.labels_).clone().to('cuda')\n",
    "    return kmeans_labels\n",
    "\n",
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot\n",
    "\n",
    "\n",
    "def load_data(path=\"D:/python/GCN/DeepGraphClustering/data/cora/\", dataset=\"cora\"):\n",
    "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
    "    print('Loading {} dataset...'.format(dataset))\n",
    "    \n",
    "    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset),\n",
    "                                        dtype=np.dtype(str))\n",
    "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
    "    labels = encode_onehot(idx_features_labels[:, -1])\n",
    "\n",
    "    # build graph\n",
    "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
    "    idx_map = {j: i for i, j in enumerate(idx)}\n",
    "    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset),\n",
    "                                    dtype=np.int32)\n",
    "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
    "                     dtype=np.int32).reshape(edges_unordered.shape)\n",
    "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                        shape=(labels.shape[0], labels.shape[0]),\n",
    "                        dtype=np.float32)\n",
    "\n",
    "    # build symmetric adjacency matrix\n",
    "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "    features = normalize(features)\n",
    "    adj = normalize(adj + sp.eye(adj.shape[0])) #ここでA = A+I 更に D^-1*A までしてる\n",
    "\n",
    "    idx_train = range(140)\n",
    "    idx_val = range(200, 500)\n",
    "    idx_test = range(500, 1500)\n",
    "\n",
    "    features = torch.FloatTensor(np.array(features.todense()))\n",
    "    labels = torch.LongTensor(np.where(labels)[1])\n",
    "    adj = sparse_mx_to_torch_sparse_tensor(adj) #ここで各入力A, X, lをtensor型に変更\n",
    "    \n",
    "    idx_train = torch.LongTensor(idx_train)\n",
    "    idx_val = torch.LongTensor(idx_val)\n",
    "    idx_test = torch.LongTensor(idx_test)\n",
    "\n",
    "    return adj, features, labels, idx_train, idx_val, idx_test\n",
    "\n",
    "\n",
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)\n",
    "\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "import scipy.sparse as sp \n",
    "import glob\n",
    "\n",
    "dataset = 'D:\\python\\GCN\\DeepGraphClustering\\data\\MUTAG'\n",
    "n_of_labels = 7\n",
    "batch_size = 3\n",
    "n_of_nodes = np.zeros(batch_size, dtype=int)\n",
    "\n",
    "def encode_onehot(val):\n",
    "    return np.array([1 if i==val else 0 for i in range(n_of_labels)])\n",
    "\n",
    "def size_loader(ls):\n",
    "    labels = []\n",
    "    for i, l in enumerate(ls):\n",
    "        if(l == '\\n'):\n",
    "            break\n",
    "    return i/4\n",
    "\n",
    "def data_loader(ls):\n",
    "    labels = []\n",
    "    for i, l in enumerate(ls):\n",
    "        if(l == '\\n'):\n",
    "            break\n",
    "    nodes = [ls[j] for j in range(i)]\n",
    "    edges = [ls[k] for k in range(i+1, len(ls))]\n",
    "\n",
    "    map_ = {}\n",
    "    for i, n in enumerate(nodes):\n",
    "        if(i%4==1):\n",
    "            idx = int(re.findall(r'id (\\d+)', n)[0])\n",
    "            map_[idx] = int((i+3)/4)-1\n",
    "        if(i%4==2):\n",
    "            n = n.replace('\"', '')\n",
    "            n = int(re.findall(r'label (\\d)', n)[0])\n",
    "            labels.append(n)\n",
    "    \n",
    "    pairs = []\n",
    "    for i, e in enumerate(edges):\n",
    "        if(i%5==1):\n",
    "            source = int(re.findall(r'source (\\d+)', e)[0])\n",
    "        if(i%5==2):\n",
    "            target = int(re.findall(r'target (\\d+)', e)[0])\n",
    "            pairs.append((map_[source], map_[target]))\n",
    "\n",
    "    X = np.array([encode_onehot(l) for i, l in enumerate(labels)])\n",
    "    A = np.zeros((len(labels), len(labels)), dtype=int)\n",
    "    for i, j in pairs:\n",
    "        A[i][j] = 1\n",
    "    return csr_matrix(X), coo_matrix(A)\n",
    "\n",
    "with open(dataset + r'\\0.gml', 'r') as f:\n",
    "    ls = f.readlines()\n",
    "    ls = ls[2:-2]\n",
    "    \n",
    "Xs, As = [], []\n",
    "gmls = glob.glob('D:\\python\\GCN\\DeepGraphClustering\\data\\MUTAG\\*.gml')\n",
    "for i in range(batch_size):\n",
    "    with open(gmls[i], 'r') as f:\n",
    "        ls = f.readlines()\n",
    "        ls = ls[2:-2]\n",
    "    n_of_nodes[i] = size_loader(ls)\n",
    "\n",
    "A = csr_matrix(([], ([], [])), shape=(0, np.sum(n_of_nodes)), dtype=int)\n",
    "X = csr_matrix(([], ([], [])), shape=(0, n_of_labels), dtype=int)\n",
    "for i in range(batch_size):\n",
    "    with open(gmls[i], 'r') as f:\n",
    "        ls = f.readlines()\n",
    "        ls = ls[2:-2]\n",
    "    x, a = data_loader(ls)\n",
    "    print(x.toarray(), end='\\n\\n')\n",
    "    X = sp.vstack((X, x), format='csr')\n",
    "    Ai = csr_matrix(([], ([], [])), shape=(n_of_nodes[i], 0), dtype=int)\n",
    "    for j in range(batch_size):\n",
    "        if(i==j):\n",
    "            Ai = sp.hstack((Ai, a), format='csr')\n",
    "        else:\n",
    "            x = csr_matrix(([], ([], [])), shape=(n_of_nodes[i], n_of_nodes[j]), dtype=int)\n",
    "            Ai = sp.hstack((Ai, x), format='csr')\n",
    "    A = sp.vstack((A, Ai), format='csr')\n",
    "\n",
    "X, A = X.toarray(), A.toarray()\n",
    "np.savetxt('D:\\python\\GCN\\DeepGraphClustering\\data\\X.csv', X, fmt='%d')\n",
    "np.savetxt('D:\\python\\GCN\\DeepGraphClustering\\data\\A.csv', A, fmt='%d')\n",
    "\n",
    "with open(dataset + r'\\Labels.txt', 'r') as f:\n",
    "    classes = np.array([int(c.strip()) for c in f.readlines()])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
